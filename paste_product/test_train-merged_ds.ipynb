{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb_import import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "yolo_dir = Path.home()/'new_yolov5/yolov5'\n",
    "if yolo_dir.is_dir():\n",
    "    sys.path.append(str(yolo_dir))\n",
    "\n",
    "from utils.tools.general import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9808431b0b4012bfb8151a004a7b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5143deef04f045e9a31acd112b837c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19222 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695282011bbe4f1491f046e637bec63a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40670 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c882ead04bbd48cc87151b55a13a4ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5298 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cheeyung/new_yolov5/yolov5/data/test_sampled_coco2017/train_images.cache\n",
      "/home/cheeyung/new_yolov5/yolov5/data/test_sampled_coco2017/val_images.cache\n",
      "yaml_dir:  /home/cheeyung/new_yolov5/yolov5/data/test_sampled_coco2017\n",
      "train_txt:  ('/home/cheeyung/new_yolov5/yolov5/data/test_sampled_coco2017/train_images.txt', True)\n",
      "val_txt:  ('/home/cheeyung/new_yolov5/yolov5/data/test_sampled_coco2017/val_images.txt', True)\n",
      "Overwriting /home/cheeyung/new_yolov5/yolov5/data/test_sampled_coco2017/hyp_custom.yaml\n"
     ]
    }
   ],
   "source": [
    "%run ./create_yaml.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cfg_yaml': PosixPath('/home/cheeyung/new_yolov5/yolov5/models/yolov5m.yaml'),\n",
      " 'data_yaml': PosixPath('/home/cheeyung/new_yolov5/yolov5/data/test_sampled_coco2017/data.yaml'),\n",
      " 'dpath': PosixPath('/mnt/disks/datasets'),\n",
      " 'hyp_custom_yaml': PosixPath('/home/cheeyung/new_yolov5/yolov5/data/test_sampled_coco2017/hyp_custom.yaml'),\n",
      " 'train_txt': PosixPath('/home/cheeyung/new_yolov5/yolov5/data/test_sampled_coco2017/train_images.txt'),\n",
      " 'val_txt': PosixPath('/home/cheeyung/new_yolov5/yolov5/data/test_sampled_coco2017/val_images.txt')}\n"
     ]
    }
   ],
   "source": [
    "'''important variables from create_yaml'''\n",
    "from pprint import pprint\n",
    "\n",
    "def show_configs():\n",
    "    # print(f\"dpath:  {dpath}\")\n",
    "    pprint({\"dpath\":  dpath,\n",
    "     \"train_txt\":  train_txt,\n",
    "     \"val_txt\":  val_txt,\n",
    "     \"data_yaml\":  data_yaml,\n",
    "     \"hyp_custom_yaml\":  hyp_custom_yaml,\n",
    "     \"cfg_yaml\":  cfg_yaml\n",
    "    })\n",
    "\n",
    "\n",
    "show_configs()\n",
    "# str(train_txt), str(val_txt), str(data_yaml), str(hyp_custom_yaml), cfg_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msilkron_cy\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    }
   ],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create filelist txt for val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# overwrite hyp yaml (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyp_custom_yaml:  /home/cheeyung/new_yolov5/yolov5/data/test_sampled_coco2017/hyp_custom.yaml\n"
     ]
    }
   ],
   "source": [
    "print(f\"hyp_custom_yaml:  {hyp_custom_yaml}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/cheeyung/new_yolov5/yolov5/data/test_sampled_coco2017/hyp_custom.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile {hyp_custom_yaml}\n",
    "\n",
    "lr0: 0.00428\n",
    "lrf: 0.106\n",
    "momentum: 0.878\n",
    "weight_decay: 0.00036\n",
    "warmup_epochs: 1.08\n",
    "warmup_momentum: 0.547\n",
    "warmup_bias_lr: 0.0471\n",
    "box: 0.0264\n",
    "cls: 0.263\n",
    "cls_pw: 1.01\n",
    "obj: 0.301\n",
    "obj_pw: 1.25\n",
    "iou_t: 0.3\n",
    "anchor_t: 3.29\n",
    "# anchors: 3.53\n",
    "fl_gamma: 0.0\n",
    "hsv_h: 0.01\n",
    "hsv_s: 0.2\n",
    "hsv_v: 0.2\n",
    "degrees: 0.876\n",
    "translate: 0.05\n",
    "scale: 0.05\n",
    "shear: 0.05\n",
    "perspective: 0.0\n",
    "flipud: 0.3\n",
    "fliplr: 0.3\n",
    "mosaic: 0\n",
    "mixup: 0.0\n",
    "copy_paste: 0.0  # segment copy-paste (probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ci_test_train(img_size):\n",
    "    '''continuous intergration testing '''\n",
    "\n",
    "    !python train.py --project {PROJECT} \\\n",
    "        --name {save_name} \\\n",
    "        --hyp {hyp_custom_yaml} \\\n",
    "        --data {data_yaml} \\\n",
    "        --cfg {cfg_yaml} \\\n",
    "        --epochs {epochs} \\\n",
    "        --batch-size {batch_size} \\\n",
    "        --img-size {img_size} \\\n",
    "        # --save_period & \\\n",
    "        --noautoanchor\n",
    "\n",
    "def training_cli():\n",
    "    !python train.py --project {PROJECT} \\\n",
    "        --name {save_name} \\\n",
    "        --hyp {hyp_custom_yaml} \\\n",
    "        --data {data_yaml} \\\n",
    "        --cfg {cfg_yaml} \\\n",
    "        --epochs {epochs} \\\n",
    "        --batch-size {batch_size} \\\n",
    "        --img-size {img_size} \\\n",
    "        --save_period 2 \\\n",
    "        --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cheeyung/new_yolov5/yolov5\n",
      "{'cfg_yaml': PosixPath('/home/cheeyung/new_yolov5/yolov5/models/yolov5n.yaml'),\n",
      " 'data_yaml': PosixPath('/home/cheeyung/new_yolov5/yolov5/data/test_sampled_coco2017/data.yaml'),\n",
      " 'dpath': PosixPath('/mnt/disks/datasets'),\n",
      " 'hyp_custom_yaml': PosixPath('/home/cheeyung/new_yolov5/yolov5/data/test_sampled_coco2017/hyp_custom.yaml'),\n",
      " 'train_txt': PosixPath('/home/cheeyung/new_yolov5/yolov5/data/test_sampled_coco2017/train_images.txt'),\n",
      " 'val_txt': PosixPath('/home/cheeyung/new_yolov5/yolov5/data/test_sampled_coco2017/val_images.txt')}\n"
     ]
    }
   ],
   "source": [
    "# hyp_custom_yaml = hyp_custom_yaml.resolve()\n",
    "# cfg_yaml = (yolo_dir/'models/yolov5m.yaml').resolve()\n",
    "# data_yaml = data_yaml.resolve()\n",
    "\n",
    "%cd {yolo_dir}\n",
    "\n",
    "cfg_yaml = (yolo_dir/'models/yolov5n.yaml').resolve()\n",
    "show_configs()\n",
    "# (hyp_custom_yaml, cfg_yaml, data_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msilkron_cy\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5n.pt, cfg=/home/cheeyung/new_yolov5/yolov5/models/yolov5n.yaml, data=/home/cheeyung/new_yolov5/yolov5/data/test_sampled_coco2017/data.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=1, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=cpu, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mâš ï¸ YOLOv5 is out of date by 124 commits. Use `git pull` or `git clone https://github.com/cysilkron/temp_yolo` to update.\n",
      "YOLOv5 ðŸš€ v6.0-10-gdd97a72 torch 1.7.0+cu110 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfresh-dragon-57\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/silkron_cy/YOLOv5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/silkron_cy/YOLOv5/runs/2ymgy06m\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /home/cheeyung/new_yolov5/yolov5/wandb/run-20211208_043335-2ymgy06m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 10745... (success).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 â–\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP_0.5 0.00121\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   metrics/mAP_0.5:0.95 0.0007\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/precision 0.00274\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         metrics/recall 0.02564\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/box_loss 0.11819\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/cls_loss 0.08327\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         train/obj_loss 0.05507\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/box_loss 0.10213\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/cls_loss 0.06462\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:           val/obj_loss 0.03443\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr0 7e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr1 7e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  x/lr2 0.09937\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 42 media file(s), 1 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mfresh-dragon-57\u001b[0m: \u001b[34mhttps://wandb.ai/silkron_cy/YOLOv5/runs/2ymgy06m\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: ./wandb/run-20211208_043335-2ymgy06m/logs/debug.log\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "im_size = 640\n",
    "# im_size = 320\n",
    "!python train.py --img {im_size} --batch 16 --weights yolov5n.pt --cfg {cfg_yaml} --epochs 1 --device 'cpu' --data {data_yaml}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msilkron_cy\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "usage: train.py [-h] [--weights WEIGHTS] [--cfg CFG] [--data DATA] [--hyp HYP]\n",
      "  --hyp HYP             hyperparameters path\n",
      "  --evolve [EVOLVE]     evolve hyperparameters for x generations\n"
     ]
    }
   ],
   "source": [
    "!python train.py --help | grep hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''jump'''\n",
    "# img_size = 1024\n",
    "\n",
    "img_size = 640\n",
    "# batch_size = 32 if img_size < 1024 else 16\n",
    "batch_size = 4\n",
    "print(f\"batch_size:  {batch_size}\")\n",
    "\n",
    "\n",
    "PROJECT = 'fake_coco128--debug'\n",
    "# PROJECT = 'lightbox_val_merged--debug'\n",
    "save_name = 'v6_master--hsv'\n",
    "# save_name = f'labeled_coco128_sample120--{img_size}-'\n",
    "epochs = 1\n",
    "\n",
    "# ci_test_train(img_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PROJECT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4829/3260562142.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mplot_train_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPROJECT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'PROJECT' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_train_img(project, save_name):\n",
    "    result_dirs = (yolo_dir/project).ls(save_name+'*')\n",
    "    \n",
    "    if not any(p.is_dir() for p in result_dirs):\n",
    "        print('Result Directory not found')\n",
    "    else:\n",
    "        latest_run = sorted(result_dirs)[-1]\n",
    "        img_paths = latest_run.ls('train_batch*.jpg')\n",
    "\n",
    "        if len(img_paths):\n",
    "            print('train img found')\n",
    "            [ia.imshow(imageio.imread(im)) for im in img_paths]\n",
    "    \n",
    "\n",
    "plot_train_img(PROJECT, save_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parse arg for debug training in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from test_train import *\n",
    "\n",
    "\n",
    "# parse_arg_notetbook = (yolo_dir/'paste_product'/'parse_args.ipynb')\n",
    "# if parse_arg_notetbook.is_file():\n",
    "#     !jupyter nbconvert --to script {parse_arg_notetbook} \n",
    "# else:\n",
    "#     raise ValueError('Notebook not found')\n",
    "\n",
    "# from paste_product.parse_args import get_default_args, merge_args, parse_args, print_if_keys_in_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_args(train_options, file_path_args):\n",
    "    merged_train_args = merge_args(train_options, file_path_args)\n",
    "\n",
    "    print_if_keys_in_dict(train_options, merged_train_args)\n",
    "    print_if_keys_in_dict(file_path_args, merged_train_args)\n",
    "    print_if_keys_in_dict(get_default_args(), merged_train_args)\n",
    "\n",
    "    train_namespace = parse_args(train_options, file_path_args)\n",
    "\n",
    "    return train_namespace\n",
    "\n",
    "def parse_debug_opt(train_options, file_path_args):\n",
    "    opt = init_args(train_options, file_path_args)\n",
    "    opt.resume = False\n",
    "    return opt\n",
    "\n",
    "def training_with_opt_in_nb():\n",
    "\n",
    "    def debug_training():\n",
    "        opt = parse_debug_opt(train_options, file_path_args)\n",
    "        print(opt)\n",
    "        main(opt)\n",
    "\n",
    "\n",
    "\n",
    "    file_path_args = {\n",
    "        'hyp' : hyp_custom_yaml,\n",
    "        'data' : data_yaml,\n",
    "        'weights' : yolo_dir/'yolov5s.pt',\n",
    "        'cfg' : yolo_dir/ 'models/yolov5s.yaml'\n",
    "    }\n",
    "\n",
    "\n",
    "    train_options = {\n",
    "        'project' : 'lightbox_val_merged--debug',\n",
    "        # 'name' : 'solved_filter_front_img_in_dataset',\n",
    "        'name' : 'img_not_log_in_notebook_arg',\n",
    "\n",
    "        'epochs' : 1,\n",
    "        'batch_size' : 16,\n",
    "        'imgsz' : 160,\n",
    "        'nosave' : False,\n",
    "        'upload_dataset': False,\n",
    "        'save_period': -1,\n",
    "    }\n",
    "\n",
    "    # init_args(train_options, file_path_args)\n",
    "    debug_training()\n",
    "\n",
    "# training_with_opt_in_nb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## json dump namespace to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_options' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_56268/3967507451.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdump_nampespace_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse_debug_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_options' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# import json\n",
    "\n",
    "# def dump_nampespace_to_file(namespace_opt, save_file='opt_dict.txt'):\n",
    "#     opt_dict = vars(namespace_opt)\n",
    "#     for k,v in opt_dict.items():\n",
    "#         if isinstance(v, Path):\n",
    "#             opt_dict[k] = str(v)\n",
    "#     with open(save_file, 'w') as f:\n",
    "#         json.dump(opt_dict, f)\n",
    "\n",
    "\n",
    "# dump_nampespace_to_file(parse_debug_opt(train_options, file_path_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndump_nampespace_to_file -> train_cli_opt\\ninit_args(train_options, file_path_args) -> notebook_opt\\n\\ncompare_with_df(train_cli_opt, vars(notebook_opt))\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "dump_nampespace_to_file -> train_cli_opt\n",
    "init_args(train_options, file_path_args) -> notebook_opt\n",
    "\n",
    "compare_with_df(train_cli_opt, vars(notebook_opt))\n",
    "'''\n",
    "\n",
    "# test_db_opt = init_args(train_options, file_path_args)\n",
    "# pprint(vars(test_db_opt))\n",
    "\n",
    "# col = 'hyp'\n",
    "# print(f\"opt_df['ori'][{col}]:  {opt_df['ori'][col]}\")\n",
    "# f\"opt_df['mine'][{col}]:  {opt_df['mine'][col]}\"\n",
    "\n",
    "# with open('opt_dict.txt', 'r') as f:\n",
    "#     json_ori_train_opt = json.load(f)\n",
    "\n",
    "# opt_df = pd.DataFrame([json_ori_train_opt, vars(test_db_opt)], index=['ori', 'mine']).T\n",
    "# has_same_opt = (opt_df['ori'] == opt_df['mine'])\n",
    "# opt_df[~has_same_opt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debug test\n",
    "(nid to remove label's .cache file)\n",
    "\n",
    "- real labeled coco128\n",
    "    - by dir (all img) = pass\n",
    "    - by txt (sample 10) = train not upload, val img pass\n",
    "    - by txt (sample 120) \n",
    "        - im_size 320 = pass\n",
    "        - im_size 160 = pass\n",
    "\n",
    "- fake labeled coco128 (dummy label with only 13 class)\n",
    "    - by txt (sample 120) \n",
    "        - im_size 160 = pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "04ddf35340c1ce64f127aae7421c8cf99ef6dbb93c27b1d0248a5253fd4efee9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('yolov5': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
